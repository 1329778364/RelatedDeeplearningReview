# RelatedDeeplearningReview
Collect reviews of the related DeepLearning

|Tag|Document title|Published|Source|Area|    Comment        |other|
|:--|:--|:--|:--|:--|:--|:--|
|Meta Learning|Learning to Learn with Gradients|2018|[https://cloudfront.escholarship.org/dist/prd/content/qt0987d4n3/qt0987d4n3.pdf](https://cloudfront.escholarship.org/dist/prd/content/qt0987d4n3/qt0987d4n3.pdf)||作者Chelsea Finn，现任Google Brain研究科学家，同时也是伯克利人工智能研究实验室(BAIR)的博士后。其博士毕业于伯克利计算机系，拥有强大的学术背景，可以算是AI圈最牛逼的博士之一了。她的博士论文——基于梯度的元学习（Learning to Learn with Gradients）很值得一读，该论文系统性地阐述了Meta Learning以及她提出的MAML的方法和相关改进。作者从Meta Learning问题出发，然后提出了MAML理论，再进行一系列基于该理论的应用尝试。感兴趣的同学可以仔细品味这一系统性的博士论文和其代表性工作。|链接：链接：https://pan.baidu.com/s/1A9Hs3kllpIppXBNqrmYqVA 提取码：x0np |
|Python|Python进阶|2018|http://interpy.eastlakeside.com/||《Intermediate Python》的中文译本，IntermediatePython这本书具有如下几个优点：简单、易读、易译。这些都不是重点，重点是：它是一本开脑洞的书。无论你是Python初学者，还是Python高手，它显现给你的永远是Python里最美好的事物。|英文版：http://book.pythontips.com/en/latest/||
|Statistical Learning|CS229T/STAT231:Statistical Learning Theory(Winter 2016)|2018|[https://github.com/percyliang/cs229t/blob/master/lectures/notes.pdf](https://github.com/percyliang/cs229t/blob/master/lectures/notes.pdf)||CS229T/STAT231 是由斯坦福大学开设的统计学习理论课程，着重于对机器学习算法统计特性的理论理解，涉及机器学习算法何时起作用和原因、如何形式化算法从数据中学习的含义、如何使用数学思维来设计更好的机器学习方法等基本课题。由斯坦福大学计算机系教授 Percy Liang 近期公布的 CS229T/STAT231 的学习笔记。|||
|Incremental Learning|[GitHub] Awesome-Incremental-Learning||[https://github.com/xialeiliu/Awesome-Incremental-Learning](https://github.com/xialeiliu/Awesome-Incremental-Learning)||关于增量学习/终生学习论文资源列表|||
|Optimization|Optimization Everywhere: Convex, Combinatorial, and Economic|2018|[https://www2.eecs.berkeley.edu/Pubs/TechRpts/2018/EECS-2018-185.pdf](https://www2.eecs.berkeley.edu/Pubs/TechRpts/2018/EECS-2018-185.pdf)||作者Sam Wong是伯克利 the Theory group的研究生，近期公开发布了他的博士论文，该论文系统性的论述了优化问题广泛的应用价值，并提出了自己的新式算法，非常有学习价值|||
|NLP|Analysis Methods in Neural Language Processing: A Survey|2018|[https://arxiv.org/abs/1812.08951](https://arxiv.org/abs/1812.08951)||MIT&哈佛大学最新综述文章：NLP模型的分析方法               自然语言处理领域今年来取得了很多令人瞩目的进展，神经网络模型逐步取代了传统模型的应用。目前，学术界已经提出了很多新式模型，其中许多方法被认为是不透明的，这使得研究人员需要以更新颖的方法进行分析，来解释神经网络。为此Yonatan Belinkov与James Glass对NLP中的分析方法进行了回顾。同时，根据研究趋势对其进行了分类，强调了现有方法的局限性，并指出了未来的潜在方向。|[https://github.com/boknilev/nlp-analysis-methods](https://github.com/boknilev/nlp-analysis-methods)||
| Data Science|Foundations of Data Science|2018|[https://www.cs.cornell.edu/jeh/book.pdf](https://www.cs.cornell.edu/jeh/book.pdf)||康奈尔大学计算机科学系John E. Hopcroft主编的的《数据科学基础》|||
|Deep Learning| Introduction to Deep Learning|2018|[http://zh.d2l.ai/](http://zh.d2l.ai/)||MXNet 作者李沐大神、Aston Zhang 等人所著的交互式书籍《动手学深度学习》推出了在线预览版，面向在校学生、工程师和研究人员，旨在帮助读者从入门到深入、动手学习深度学习，即使是零基础的读者也完全适用。近日，李沐和他在CMU的导师Alex Smola计划在加州大学伯克利分校开设《深度学习》课程，动手学深度学习，是想深入学习DL不可多得的一门课程。|||
|Graph Neural Networks|Graph Neural Networks: A Review of Methods and Applications|2018|[https://arxiv.org/abs/1812.08434v1](https://arxiv.org/abs/1812.08434v1)||今年以来，DeepMind、Google大脑、MIT等各大研究机构相继发表了一系列的关于图深度学习的论文，包括关系性RNN、关系性深度强化学习、图卷积神经网络等，是当前的研究热点。最近，清华大学孙茂松老师课题组在ArXiv上发表了一篇《图神经网络》综述论文，详细全面总结了最新图神经网络的模型，应用和未来研究方向，是研究该领域的重要的参阅资料。|||
|Deep Reinforcement Learning|Acquiring Diverse Robot Skills via Maximum Entropy Deep Reinforcement Learning|2018|[https://www2.eecs.berkeley.edu/Pubs/TechRpts/2018/EECS-2018-176.pdf](https://www2.eecs.berkeley.edu/Pubs/TechRpts/2018/EECS-2018-176.pdf)||作者Tuomas Haarnoja是伯克利人工智能研究实验室(BAIR)的博士生，由Pieter Abbeel和Sergey Levine指导，他研究兴趣是建立对深度强化学习算法更好的理解，并开发新的解决方案，以启发现实机器人应用，需要良好的样本复杂性和安全的探索。他最出名的工作是最大熵强化学习，它为学习样本高效可靠的随机策略提供了一个理论基础框架，并将其应用于机器人操纵和运动。|作者首页：https://people.eecs.berkeley.edu/~haarnoja/||
|TensorFlow|TensorFlow内核剖析|2018|[https://github.com/horance-liu/tensorflow-internals/blob/master/tensorflow-internals.pdf](https://github.com/horance-liu/tensorflow-internals/blob/master/tensorflow-internals.pdf)||这是一本剖析Tensorflow 内核工作原理的书籍，并非讲述如何使用 TensorFlow 构建机器学习模型，也不会讲述应用 TensorFlow 的最佳实践。本书将通过剖析 TensorFlow 源代码的方式，揭示 TensorFlow 的系统架构、领域模型、工作原理、及其实现模式等相关内容，以便揭示内在的知识。|||
|Self Supervised Learning|Yann Lecun自监督学习指南|2018|链接: 接: https://pan.baidu.com/s/1_turB7Cu9GzQ1Fh2vLJ1uw 提取码: a768||Yann Lecun是卷积网络模型的发明者，该模型被广泛地应用于模式识别应用中，因此他也被称为卷积网络之父，是公认的世界人工智能三巨头之一。 2018年11月08日，他来到加州大学圣巴巴拉分校，为在场师生作了一场关于自监督学习的前沿报告，近日他在twitter上公开了报告的全程录像以及Slides全文|[视频：  https://ucsb.app.box.com/s/msam98ewhhk48t60p75glvm9h0fv57fl](https://ucsb.app.box.com/s/msam98ewhhk48t60p75glvm9h0fv57fl)||
|Machine Learning|Mathematics For Machine Learning|2017(updating)|[https://github.com/mml-book/mml-book.github.io](https://github.com/mml-book/mml-book.github.io)||伦敦帝国理工学院的深度学习数学讲稿笔记，其目标在于为学生们提供基本的数学背景以及必要的技能，来理解、设计、实施现代的统计机器学习方法与推理机制，例如PCA（Principal Component Analysis）、Linear Discriminant Analysis、Bayesian Linear Regression 与 SVM（Support Vector Machines）。|||
|Machine Learning|The Hundred-Page Machine Learning Book|2018|链接：链接：https://pan.baidu.com/s/1Nj6QI0_AtarAgKZw448qEg 提取码：ty76 ||作者Andriy Burkov放出了他撰写的《The Hundred-Page Machine Learning Book》的这本书的最新版，只有100页，目标是任何只要有基础数学知识的人都能看懂的机器学习书籍。这本书的十一个章节最新版都已经在网站上公开，本书将涵盖监督学习和非监督学习两大部分、包括神经网络、深度学习以及计算机科学、数学和统计学中最重要的一些机器学习问题。这本书浅显易懂，适合初学者学习和收藏！|[http://themlbook.com/wiki/doku.php](http://themlbook.com/wiki/doku.php)||
| Autoencoder|Recent Advances in Autoencoder-Based Representation Learning|2018|[https://arxiv.org/pdf/1812.05069.pdf](https://arxiv.org/pdf/1812.05069.pdf)||【无监督学习】（Unsupervised Learning）现在已经成为深度学习领域的热点。和「有监督学习」相比，这种方法的最大优势就在于其无须给系统进行明确的标注（label）也能够进行学习。而自编码器作为一种经典的无监督学习方法一直广受关注。 最近Goog Brain与苏黎世理工就带来了关于自编码表示学习的综述，详细介绍了从基本的自编码到最新的各种VAE变体的研究现状。|||
|Reinforcement Learning|REINFORCEMENT LEARNING AND OPTIMAL CONTROL|2019|[http://web.mit.edu/dimitrib/www/RLbook.html](http://web.mit.edu/dimitrib/www/RLbook.html)||MIT科学家Dimitri P. Bertsekas今日发布了一份2019即将出版的《强化学习与最优控制》书稿及讲义，该专著目的在于探索这人工智能与最优控制的共同边界，形成一个可以在任一领域具有背景的人员都可以访问的桥梁。|||
||Compositional visual intelligence||链接: 接: https://pan.baidu.com/s/1BBuzBuqPFuoaompiEQVAPw 提取码 提取码: te3s ||Justin Johnson，斯坦福大学博士，导师是计算机视觉领域顶级学者李飞飞博士。研究兴趣包括计算机视觉和机器学习方面，涉及到视觉推理、视觉和语言，以及使用深层神经网络生成图像。Johnson目前是Facebook AI Research的研究科学家。从2019年秋季开始，我将加入密歇根大学计算机科学与工程专业，担任助理教授。Johnson在2018年夏天完成博士学位，其博士论文组成式视觉智能《Compositional visual intelligence》，195页详述采用组合式学习的方法对计算机视觉中图像描述、视觉问答、文本图像生成三方面的问题进行了研究，是组合式视觉智能的代表性研究工作。|[https://cs.stanford.edu/people/jcjohns/](https://cs.stanford.edu/people/jcjohns/)||
||Neural Reading Comprehension and Beyond||链接：链接：https://pan.baidu.com/s/1EFqRiI446PGffBJkOujvRg 提取码：5tnx ||陈丹琦，清华本科（姚班）,斯坦福博士即将毕业，师从Christopher Manning，毕业后成为普林斯顿大学计算机学院助理教授，在学期间曾在ACL，EMNLP，NIPS等自然语言处理与机器学习定会发表多篇文章。|[https://cs.stanford.edu/people/danqi/](https://cs.stanford.edu/people/danqi/)||
|PyToch|[Slides] EE-559 – DEEP LEARNING (SPRING 2019)||[https://fleuret.org/ee559/ee559-slides-all.zip](https://fleuret.org/ee559/ee559-slides-all.zip)||近日，在 NeurIPS 2018 大会上，Facebook 官方宣布 PyTorch 1.0 正式版发布了。如何用Pytorch1.0搞深度学习？对很多小白学生是个问题。瑞士非盈利研究机构 Idiap Research Institute的研究员FRANÇOIS FLEURET开设了一门深度学习课程(2019年秋季)，详细结合深度学习与最新Pytorch1.0来为你细致讲解，是学习Pytorch1.0深度学习不可多得的材料。|[https://fleuret.org/ee559/](https://fleuret.org/ee559/)||
|Reinforcement Learning|[Html] Key Papers in Deep RL||[https://spinningup.openai.com/en/latest/spinningup/keypapers.html](https://spinningup.openai.com/en/latest/spinningup/keypapers.html)||OpenAI 在教学资源合集 Spinning Up中发布了强化学习中的关键论文，列举了强化学习不同领域的代表性文章来指导研究者的学习。此外Spinning Up 包含清晰的 RL 代码示例、习题、文档和教程可供参考。|||
|Graphics|CreativeAI: Deep Learning for Graphics||[http://geometry.cs.ucl.ac.uk/creativeai/](http://geometry.cs.ucl.ac.uk/creativeai/)||在计算机图形学中，许多传统问题现在通过基于深度学习的数据驱动方法得到更好的解决。在越来越多的问题设置中，深层网络是最先进的，远远超过了专门手工设计的方法。本教程对深度学习的核心理论、实践和图形相关应用进行了系统性的概述。|教程；代码；PPT||
||NeruIPS 2018 所有tutorial的视频与PPT汇总【附下载】||[https://mp.weixin.qq.com/s/wiPwk-54b26fbshL3DayeA](https://mp.weixin.qq.com/s/wiPwk-54b26fbshL3DayeA)||2018年12月2日到12月8日，第三十二届NeurIPS （Conference on Neural Information Processing Systems）年度会议在蒙特利尔会议中心盛大召开。该会议汇集了机器学习和神经网络领域的顶级专家学者，为广大研究者带来了大量高质量的研究成果。会议的Tutorial环节于前日结束，小编收集了NeruIPS 2018的所有tutorial的视频和ppt，分享给大家。|||
|Unsupervised  Learning|[Slides] Unsupervised  Deep  Learning||[https://mp.weixin.qq.com/s/L4GQF0eE7MjLPrb8UygCww](https://mp.weixin.qq.com/s/L4GQF0eE7MjLPrb8UygCww)||2018年12月2日到12月8日，第三十二届NeurIPS （Conference on Neural Information Processing Systems）年度会议在蒙特利尔会议中心盛大召开。该会议汇集了机器学习和计算神经领域的顶级专家学者，为广大研究者带来了大量高质量的研究成果。本文特为大家整理了来自DeepMind与Facebook研究人员联名所作的学术报告-无监督深度学习，希望大家喜欢。|||
|NLP|Recent Trends in Deep Learning Based Natural Language Processing|2018|[https://arxiv.org/pdf/1708.02709.pdf](https://arxiv.org/pdf/1708.02709.pdf)||Tom Youn等人更新了去年发表在IEEE杂志上的重磅文章《Recent Trends in Deep Learning Based Natural Language Processing》，总结了到今年为止，基于深度学习的自然语言处理（NLP）系统和应用程序的一些最新趋势。在这篇综述中，读者可以详细了解这一年来学界的一些大动作，它包含以下主题：（1）分布式表征的兴起（例如word2vec）（2）卷积、循环和RNN（3）在强化学习中的应用（4）句子的无监督表征学习的最新进展（5）深度学习模型与记忆增强的结合。最好作者也总结后续NLP的几个重要方向：无监督学习、强化学习的一系列应用、多模态学习等。|||
| Deep Reinforcement Learning|An Introduction to Deep Reinforcement Learning|2018|[http://cn.arxiv.org/pdf/1811.12560](http://cn.arxiv.org/pdf/1811.12560)||深度强化学习是强化学习和深度学习的结合。这一领域的研究已经能够解决广泛的复杂的决策任务，这是以前无法达到的。因此，DeepRL在医疗保健、机器人技术、智能电网、金融等领域开辟了许多新的应用。本文提供了深度强化学习模型、算法和技术的介绍。特别关注的是与泛化相关的方面，以及如何在实际应用中使用深度RL。（我们假设读者熟悉基本的机器学习概念。）|||
|Deep Learning|医学影像小数据深度学习|2018|[https://mp.weixin.qq.com/s/ojlhC7vGB1r6scKipm0BjA](https://mp.weixin.qq.com/s/ojlhC7vGB1r6scKipm0BjA)||基于神经网络的深度学习方法往往需要大量标注样本，而在很多领域往往是缺乏充足样本数据的，比如在医疗领域，高质量的医疗影像大数据样本很难获取，且人工标注成本较高，缺乏病理或手术金标准。因此，亟待研究基于小样本数据集或弱标签标注的深度学习方法。将小样本弱标签的医学影像数据应用于肿瘤鉴别诊断等实际医疗场景，对于提高医学诊断准确率，具有重要现实意义。小数据深度学习是当前的一个研究热点。西北工业大学夏勇教授在VALSE Webinar带来了《医学影像小数据深度学习》的分享报告，分析在医学影像“小数据”上进行深度学习研究所面临的挑战，也将介绍报告人在应用深度学习技术进行医学影像分析的经验和体会。是小数据医疗深度学习从业者不可多得的参阅材料。|||
|Deep Learning|Deep Learning cheatsheets for Stanford's CS 230||[https://github.com/afshinea/stanford-cs-230-deep-learning](https://github.com/afshinea/stanford-cs-230-deep-learning)||斯坦福CS230:Deep Learning 课程，是斯坦福每年秋季开设的深度学习课程，由Andrew Ng 以及 Kian Katanforoosh执教，内容涵盖CNN、RNN、LSTM、Adam等等方面。斯坦福的两位研究生同学Afshine Amidi，Shervine Amidi 将其中的重要知识点拆解出来，整理成Cheatsheet。小编拜读后，觉得内容详实、结构清晰，特分享给大家。|||
|NLP|[Slides]  NLP:its progress,opportunities,and challenges|2018|[https://mp.weixin.qq.com/s/bEYBgIoJzqMBp9YFTU10-Q](https://mp.weixin.qq.com/s/bEYBgIoJzqMBp9YFTU10-Q)||周明老师是微软亚洲研究院的副院长，国际计算语言学协会（ACL）候任主席，他带领团队进行了微软输入法、英库词典（必应词典）、中英翻译、微软中国文化系列（微软对联、微软字谜、微软绝句）等重要产品和项目的研发，前不久，周明老师在CCF-AI会议上，做了：自然语言处理：进展、机遇与挑战的演讲，对自然语言处理的现状和未来做了介绍，小编听后受益匪浅，拿来跟大家分享。|||
|Reinforcement Learning|[Slides]Stochastic Approximation and Reinforcement Learning|2018|[https://mp.weixin.qq.com/s/tZjIdNSLvIVzho-IlCvm6A](https://mp.weixin.qq.com/s/tZjIdNSLvIVzho-IlCvm6A)||随着Alpha Go的成功，强化学习始终是人们谈论的焦点。本文为大家编译了来自佛罗里达大学的Adithya M. Devraj分享的随机近似与强化学习教程，希望对大家的理论学习有所帮助。|||
|Computer Version|Computer Version|2018|[http://imag.pub.ro/~rasche/course/compvis/compvis1.pdf](http://imag.pub.ro/)||本文是计算机科学家Christoph Rasche撰写的一份计算机视觉方面的系列教程，从传统的图像处理、特征提取到近几年很热的深度神经网络，以及深度学习方法在目标检测、图像检索、图像分割、目标跟踪等一系列前沿的介绍。教程也附详细的代码（Matlab 和 Python），建议初学者收藏学习。另外，其网站还有机器学习相关教程|[https://sites.google.com/site/rasche15/techpreneur-faq](https://sites.google.com/site/rasche15/techpreneur-faq)||
|Computer Version|[PPT] Uncertainty-aware food analysis by Deep Learning|2018|[https://mp.weixin.qq.com/s/o50c2cMjUSmR8Ea6v925_w](https://mp.weixin.qq.com/s/o50c2cMjUSmR8Ea6v925_w)||近期，西班牙巴塞罗那大学数学系MAIA部门的副教授 Petia Radeva 在人工智能国际会议 A2IC 2018（Artificial Intelligence International Conference）上作了一场关于食物图像分析的报告，详细讲解了当前计算机视觉中食物图像识别相关研究和应用。PPT内容深入浅出，也分析了“为什么食物图像分析需要使用深度学习？”以及当前遇到的挑战，比如大规模食物数据集的缺失，食物之间内部不同类的不确定性等等，最后也提出了一系列相关方法来尝试解决这些问题，对食物图像识别分析的同学可以仔细学习。|||
|Explain|A Survey of Methods for Explaining Black Box Models|2018|[http://cn.arxiv.org/pdf/1802.01933](http://cn.arxiv.org/pdf/1802.01933)||最近一期的计算机顶级期刊ACM Computing Surveys (CSUR)出版，包含了来自意大利比萨大学的研究人员发布的一篇构建机器学习可解释性综述论文《A Survey of Methods for Explaining Black Box Models》，详细阐述了解释黑盒机器学习模型的术语概念以及相关方法，是构建可解释模型的重要指南.|||
|Text Production|Deep Learning Approaches to Text Production|2018|[https://mp.weixin.qq.com/s/zgmpxfpn2OkPflZRpfrD7A](https://mp.weixin.qq.com/s/zgmpxfpn2OkPflZRpfrD7A)||文本生成是许多NLP应用程序的关键组件。在数据驱动方法中，它用语言表达知识库的内容或从丰富的语言产生自然英语句子表示，例如依赖树或抽象含义表示。另一方面，在文本驱动方法中，文本生成在句子压缩，句子融合，文本摘要和端到端对话系统中都有应用。随着编码-解码器模型在建模序列等任务（如机器翻译）中的成功，深度学习模型已成功应用于各种文本生成任务。本教程将介绍用于文本生成的神经模型的基础知识和研究动向。|||
|Machine Learning|[Tutorial] 100-Days-Of-ML-Code||[https://github.com/Avik-Jain/100-Days-Of-ML-Code](https://github.com/Avik-Jain/100-Days-Of-ML-Code)||推荐一个Github上的机器学习集：100 Days of ML Coding（机器学习100天），从第一天的数据预处理、第二天的简单线性回归到第54天的层次聚类等，数据和代码非常详细，希望机器学习感兴趣的读者收藏和学习！|中文连接：https://github.com/MLEveryday/100-Days-Of-ML-Code||
|Evaluation|Model Evaluation, Model Selection, and Algorithm Selection in Machine Learning|2018|[https://sebastianraschka.com/pdf/manuscripts/model-eval.pdf](https://sebastianraschka.com/pdf/manuscripts/model-eval.pdf)||无论在学术界还是工业界如何正确使用模型评估、模型选择和算法选择技术来达到预期的效果，一直是人们争相探讨的热点。来自威斯康星大学的Sebastian Raschka博士近期分享了一个49页的小册子，系统性的阐述了上述几个问题，并详细分析了各个算法的优缺点，希望这个小册子能帮到你。|||
|NLP|Joint Models for NLP |2018|[http://www.cips-cl.org/static/CCL2017/slides/T2.pdf](http://www.cips-cl.org/static/CCL2017/slides/T2.pdf)||西湖大学张岳博士在EMNLP2018 上做了《Joint Models for NLP 》的Tutorial。|||
|TensorFlow|《简单粗暴TensorFlow》教程||[https://www.tensorflowers.cn/t/6230](https://www.tensorflowers.cn/t/6230)||Xihan Li（雪麒）撰写了一份《简单粗暴TensorFlow》的入门教程，基于TensorFlow的Eager Execution（动态图）模式，力图让具备一定机器学习及Python基础的开发者们快速上手TensorFlow。|||
|NLP|An Introductory Survey on Attention Mechanisms in NLP Problems||[https://arxiv.org/pdf/1811.05544.pdf](https://arxiv.org/pdf/1811.05544.pdf)||注意力机制(Attention)起源于模仿人类的思维方式，后被广泛应用于机器翻译、情感分类、自动摘要、自动问答等、依存分析等机器学习应用中。专知编辑整理了Arxiv上一篇关于注意力机制在NLP中应用的综述《An Introductory Survey on Attention Mechanisms in NLP Problems》，并提供一些相关的代码链接。|||
|Robust|Robust Artificial Interlligence||[https://mp.weixin.qq.com/s/YI0yRgxgNE1CVY-lBwjR9g](https://mp.weixin.qq.com/s/YI0yRgxgNE1CVY-lBwjR9g)||本文为大家整理了俄勒冈州立大学的杰出教授Thomas G.Dietterich的鲁棒机器学习教程，具体内容如下。|||
|NLP|Deep Learning in Natural Language Processing||[https://mp.weixin.qq.com/s/wQEahUTHvqDNndv8Spkolw](https://mp.weixin.qq.com/s/wQEahUTHvqDNndv8Spkolw)||邓力博士及刘洋博士等人合著的 Deep Learning in Natural Language Processing 一书系统介绍深度学习在 NLP 常见问题中的应用，而且是目前对此方面研究最新、最全面的综述。 本书还对 NLP 未来发展的研究方向进行了探讨，包括神经符号整合框架、基于记忆的模型、先验知识融合以及深度学习范式（如无监督学习、生成式学习、多模学习、多任务学习和元学习等）。|||
|NLP|Writing Code for NLP Research||[https://mp.weixin.qq.com/s/Vg7CvR36_igLQbKAXU3Vrw](https://mp.weixin.qq.com/s/Vg7CvR36_igLQbKAXU3Vrw)||现代的NLP研究工作都是需要编写代码。 良好的代码可以实现快速的原型设计，简单的代码调试，实验的可控性和可视化，帮助研究人员快速准确地了解实验和模型的具体情况。而糟糕的代码往往导致拖慢研究进度，研究难以扩展，研究结果难以复现，最严重的是出现错误的研究和结论。实际上，现在研究人员也逐渐认识到好的研究工具，包括高质量的实验代码，对研究的重要性，那么如何为NLP任务写出良好的代码呢? EMNLP2018 254 页的《为NLP研究写出好代码》(Writing Code for NLP Research)的教程会给出答案。||2018.11.02|
|NLP|NLP course||[https://github.com/yandexdataschool/nlp_course](https://github.com/yandexdataschool/nlp_course)||课程为期13周，从文本嵌入分类开始，讲到Seq2Seq，再到机器翻译、对话系统、对抗学习等等，内容丰富。入门选手可以考虑。每周的课程，除了课堂视频之外，还有讨论课，大家可以 (用英文) 提问。已经讲完的课程带有视频和Python笔记，另外还有课后作业笔记。|||

